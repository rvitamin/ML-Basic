{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21141da1",
   "metadata": {},
   "source": [
    "# Где дешевле жить? Предсказание цен в Airbnb - учимся генерировать признаки и интерпретировать результаты модели"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T10:52:54.533167Z",
     "start_time": "2025-10-07T10:52:50.502166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Загружаем датасет с помощью Pandas\n",
    "data = pd.read_csv('AB_NYC_2019.csv')\n",
    "\n",
    "# Добавляем в датасет для каждого объекта расстояние до центра Манхеттена\n",
    "man_lat = (data[data['neighbourhood_group'] == 'Manhattan']['latitude'].max() - data[data['neighbourhood_group'] == 'Manhattan']['latitude'].min()) / 2\n",
    "man_lon = (data[data['neighbourhood_group'] == 'Manhattan']['longitude'].max() - data[data['neighbourhood_group'] == 'Manhattan']['longitude'].min()) / 2\n",
    "data['man_dist'] = abs(data['latitude'] - man_lat) + abs(data['longitude'] - man_lon)\n",
    "\n",
    "# Кодируем числами категориальные признаки room_type и neighbourhood_group\n",
    "le = LabelEncoder()\n",
    "data['room_type'] = le.fit_transform(data['room_type'])\n",
    "data['neighbourhood'] = le.fit_transform(data['neighbourhood'])\n",
    "data['neighbourhood_group'] = le.fit_transform(data['neighbourhood_group'])\n",
    "\n",
    "# Заполняем NoN в reviews_per_month\n",
    "data['reviews_per_month'] = data['reviews_per_month'].fillna(-999)\n",
    "\n",
    "# Отрезаем лишние колонки\n",
    "cols_to_drop = ['id', 'name', 'host_id', 'host_name', 'last_review', 'latitude', 'longitude']\n",
    "data = data.drop(columns=cols_to_drop)\n",
    "\n",
    "# Устраняем аномалии\n",
    "list_neighbourhood = list(data['neighbourhood'].unique())\n",
    "list_room_type = list(data['room_type'].unique())\n",
    "\n",
    "for i in list_neighbourhood:\n",
    "    for j in list_room_type:\n",
    "        count = data[(data['neighbourhood'] == i) & (data['room_type'] == j)].shape[0]\n",
    "        if count != 0:\n",
    "            mean = int(data[(data['neighbourhood'] == i) & (data['room_type'] == j)]['price'].mean())\n",
    "            std = data[(data['neighbourhood'] == i) & (data['room_type'] == j)]['price'].std()\n",
    "            std = int(np.nan_to_num(std, nan=0))\n",
    "            # data.loc[(data['neighbourhood'] == i) & (data['room_type'] == j) & (data['price'] > mean + 2 * std), 'price'] = mean\n",
    "            mask = (data['neighbourhood'] == i) & (data['room_type'] == j) & (data['price'] > mean + 1 * std)\n",
    "            data = data.drop(data[mask].index)\n"
   ],
   "id": "86fd817cdf13164a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T18:46:55.221902Z",
     "start_time": "2025-10-01T18:46:55.132545Z"
    }
   },
   "cell_type": "code",
   "source": "# str",
   "id": "2640ca09be557a39",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T09:01:25.164570Z",
     "start_time": "2025-10-07T09:01:25.148073Z"
    }
   },
   "cell_type": "code",
   "source": "data.isna().sum()",
   "id": "5295d15d15828b99",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighbourhood_group               0\n",
       "neighbourhood                     0\n",
       "room_type                         0\n",
       "price                             0\n",
       "minimum_nights                    0\n",
       "number_of_reviews                 0\n",
       "reviews_per_month                 0\n",
       "calculated_host_listings_count    0\n",
       "availability_365                  0\n",
       "man_dist                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T09:01:28.266201Z",
     "start_time": "2025-10-07T09:01:28.259961Z"
    }
   },
   "cell_type": "code",
   "source": "data.shape",
   "id": "b697403fe3497da1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45718, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T18:47:01.732223Z",
     "start_time": "2025-10-01T18:46:57.681960Z"
    }
   },
   "cell_type": "code",
   "source": "#",
   "id": "bfcc9e960c9a9cf2",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T10:53:34.567696Z",
     "start_time": "2025-10-07T10:52:56.969731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(['price'], axis=1),\n",
    "    data['price'],\n",
    "    test_size=0.30,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "X_test_pg1 = X_test[y_test < 100] # pg1\n",
    "y_test_pg1 = y_test[y_test < 100] # pg1\n",
    "X_test_pg2 = X_test[(y_test < 500) & (y_test >= 100)] # pg2\n",
    "y_test_pg2 = y_test[(y_test < 500) & (y_test >= 100)] # pg2\n",
    "X_test_pg3 = X_test[(y_test < 1000) & (y_test >= 500)] # pg3\n",
    "y_test_pg3 = y_test[(y_test < 1000) & (y_test >= 500)] # pg3\n",
    "X_test_pg4 = X_test[y_test >= 1000] # pg4\n",
    "y_test_pg4 = y_test[y_test >= 1000] # pg4\n",
    "# X_test_pg5 = X_test[y_test >= 5000] # pg5\n",
    "# y_test_pg5 = y_test[y_test >= 5000] # pg5\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_test_pg1 = scaler.transform(X_test_pg1) # pg1\n",
    "X_test_pg2 = scaler.transform(X_test_pg2) # pg2\n",
    "X_test_pg3 = scaler.transform(X_test_pg3) # pg3\n",
    "X_test_pg4 = scaler.transform(X_test_pg4) # pg4\n",
    "# X_test_pg5 = scaler.transform(X_test_pg5) # pg5\n",
    "\n",
    "# mod = LinearRegression()\n",
    "# mod = KNeighborsRegressor()\n",
    "mod = RandomForestRegressor(random_state=42)\n",
    "# mod = GradientBoostingRegressor()\n",
    "# mod = CatBoostRegressor(random_state=42)\n",
    "# mod = LGBMRegressor()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150],   # число деревьев\n",
    "    'max_depth': [20],          # глубина\n",
    "    'min_samples_split': [4],   # минимальное число объектов для разбиения\n",
    "    'min_samples_leaf': [7, 10]      # минимальное число объектов в листе\n",
    "}\n",
    "\n",
    "model = GridSearchCV(\n",
    "    estimator=mod,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=4,         # 4-кратная кросс-валидация\n",
    "    n_jobs=-1,    # параллельно на всех ядрах\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_test_predictions = model.predict(X_test)\n",
    "\n",
    "print(\"Best params:\", model.best_params_)\n",
    "print(\"Best RMSE:\", -model.best_score_)\n",
    "print('-----')\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_test_predictions))\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "y_test_pg1_predictions = model.predict(X_test_pg1)  # pg1\n",
    "rmse_pg1 = np.sqrt(mean_squared_error(y_test_pg1, y_test_pg1_predictions))  # pg1\n",
    "print(\"RMSE pg1:\", rmse_pg1) # pg1\n",
    "\n",
    "y_test_pg2_predictions = model.predict(X_test_pg2)  # pg2\n",
    "rmse_pg2 = np.sqrt(mean_squared_error(y_test_pg2, y_test_pg2_predictions))  # pg2\n",
    "print(\"RMSE pg2:\", rmse_pg2) # pg2\n",
    "\n",
    "y_test_pg3_predictions = model.predict(X_test_pg3)  # pg3\n",
    "rmse_pg3 = np.sqrt(mean_squared_error(y_test_pg3, y_test_pg3_predictions))  # pg3\n",
    "print(\"RMSE pg3:\", rmse_pg3) # pg3\n",
    "\n",
    "y_test_pg4_predictions = model.predict(X_test_pg4)  # pg4\n",
    "rmse_pg4 = np.sqrt(mean_squared_error(y_test_pg4, y_test_pg4_predictions))  # pg4\n",
    "print(\"RMSE pg4:\", rmse_pg4) # pg4\n",
    "\n",
    "# y_test_pg5_predictions = model.predict(X_test_pg5)  # pg5\n",
    "# rmse_pg5 = np.sqrt(mean_squared_error(y_test_pg5, y_test_pg5_predictions))  # pg5\n",
    "# print(\"RMSE pg5:\", rmse_pg5) # pg5"
   ],
   "id": "bfd912a164205ec4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Best params: {'max_depth': 20, 'min_samples_leaf': 7, 'min_samples_split': 4, 'n_estimators': 150}\n",
      "Best RMSE: 56.798244757732945\n",
      "-----\n",
      "RMSE: 57.861928588576305\n",
      "RMSE pg1: 31.488833290783756\n",
      "RMSE pg2: 63.84148522132888\n",
      "RMSE pg3: 348.33498519367174\n",
      "RMSE pg4: 896.7552402456299\n"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
